#!/bin/bash

##############################################################################################
# Intended to run hourly. Checks whether all WARCs created in the last 2 hours exist in HDFS #
# at the same location.                                                                      #
# If not, they are copied and a MapReduce job run to CDX-index them.                         #
# A full CDX can be created by sorting all the outputs.                                      #
##############################################################################################

HDFS_CDX_ROOT=/heritrix/output/wayback/cdx-index
ROOT=/heritrix/output
HOOP="http://nellie.bl.uk:14000/webhdfs/v1"
SUFFIX="?user.name=hadoop&op=GETFILESTATUS"
TMP=/tmp
#JAR=/heritrix/bin/HadoopUtils.jar
JAR=/heritrix/bin/warc-hadoop-indexer-1.1.1-SNAPSHOT-job.jar
#CLASS=uk.bl.wap.hadoop.mapreduce.cdx.ArchiveCDXGenerator
CLASS=uk.bl.wa.hadoop.mapreduce.cdx.ArchiveCDXGenerator
SPLIT=/heritrix/output/wayback/split.txt
RED=1

log()
{
        echo "[$(date "+%Y-%m-%d %H:%M:%S")] $1"
}

COUNT=0
OUTPUT="$(date +%Y%m%d%H%M%S)"
JOBS=()
while read warc
do
	TEST="$(curl --silent "$HOOP$warc$SUFFIX")"
	if [[ "$TEST" =~ "FileNotFoundException" ]]
	then
		log "Copying $warc to HDFS..."
		hadoop fs -put "$warc" "$warc"
		[[ "$warc" =~ "viral" ]] || echo "$warc" >> $TMP/$OUTPUT.job
		COUNT=$((COUNT+1))
		HDFS_LENGTH=$(curl --silent "$HOOP$warc$SUFFIX" | sed -r 's@^.+length":([0-9]+),".+$@\1@')
		DISK_LENGTH=$(stat -c %s "$warc")
		if [[ $HDFS_LENGTH -ne $DISK_LENGTH ]]
		then
			log "ERROR: WARC sizes do not match for $warc"
		fi
		JOBS+=("$(echo "$warc" | cut -d "/" -f5)")
	fi
done < <(find $ROOT/ -not -path "*/images/*" -mtime -2 -name "*.warc.gz" 2> /dev/null)
JOBS=($(printf "%q\n" "${JOBS[@]}" | sort -u))

if [[ -e $TMP/$OUTPUT.job ]] && [[ $(wc -l $TMP/$OUTPUT.job | awk '{ print $1 }') -gt 0 ]]
then
	log "Generating CDX for $OUTPUT.job in $HDFS_CDX_ROOT/$OUTPUT/..."
	hadoop fs -put $TMP/$OUTPUT.job $TMP/$OUTPUT.job && rm $TMP/$OUTPUT.job
	hadoop jar $JAR $CLASS -w -i $TMP/$OUTPUT.job -o $HDFS_CDX_ROOT/$OUTPUT/ -s $SPLIT -h -r $RED &
fi

if [[ $COUNT -eq 0 ]]
then
	exit 1
else
	log "Complete. $COUNT files copied."
	exit 0
fi
